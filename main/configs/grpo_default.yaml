model_name: Qwen/Qwen2.5-0.5B-Instruct
use_lora: true
lora_r: 16
lora_alpha: 32
lora_dropout: 0.05
num_epochs: 3
max_steps: -1
batch_size: 8
gradient_accumulation_steps: 4
learning_rate: 1.0e-05
max_length: 512
use_liger_kernel: false
output_dir: /Users/geo/facultate/rl/rl/results
logging_steps: 10
save_steps: 100
train_dataset_path: null
eval_dataset_path: null
eval_split_ratio: 0.0
experiment_name: null
reward_fn: maze
num_generations: 4
max_new_tokens: 512
temperature: 0.7
beta: 0.1
use_vllm: false
vllm_mode: colocate
vllm_gpu_memory_utilization: 0.3
vllm_tensor_parallel_size: 1
vllm_enable_sleep_mode: false
vllm_server_host: 0.0.0.0
vllm_server_port: 8000
vllm_server_timeout: 240.0
