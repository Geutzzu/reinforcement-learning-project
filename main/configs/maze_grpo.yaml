model_name: Qwen/Qwen2.5-0.5B-Instruct

use_lora: true
lora_r: 16
lora_alpha: 32
lora_dropout: 0.05

num_epochs: 1
max_steps: 500
batch_size: 4
gradient_accumulation_steps: 4
learning_rate: 0.00001
max_length: 512
use_liger_kernel: false

output_dir: /Users/geo/facultate/rl/rl/results
logging_steps: 10
save_steps: 100

train_dataset_path: /Users/geo/facultate/rl/rl/data/maze_train.parquet
eval_dataset_path: null
eval_split_ratio: 0.1

experiment_name: maze_grpo
reward_fn: maze

snapshot_prompts_count: 3
snapshot_every_n_steps: 100

num_generations: 4
max_new_tokens: 256
temperature: 0.7
beta: 0.0

use_vllm: false
